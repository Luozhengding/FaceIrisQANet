{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FaceIrisQANet.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"D2nyqtzw4CfO","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn.functional as F \n","import torch.nn as nn\n","from torch.autograd import Variable\n","import torchvision.models as models\n","from torchvision import transforms, utils\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np\n","import torch.optim as optim\n","from scipy.io import loadmat\n","from scipy.io import savemat\n","from pytorch_gdn import GDN"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AYVy5oHlRRWY","colab_type":"code","colab":{}},"source":["# network\n","device = torch.device('cuda')\n","n_channel = 1                      # (batch_size, channel, height, weight)\n","class FaceIrisQANet(nn.Module):\n","  def __init__(self):\n","      super(FaceIrisQANet,self).__init__()\n","      self.layer1 = nn.Conv2d(1, 1, kernel_size=3, stride=(1,2), padding=1, bias=True)\n","      self.layer2 = GDN(n_channel, device)\n","      self.layer3 = nn.BatchNorm2d(1)       # number of channel\n","      self.layer4 = nn.Linear(256, 16, bias=True)\n","      self.layer5 = GDN(n_channel, device)\n","      self.layer6 = nn.BatchNorm2d(1)       # number of channel\n","      self.layer7 = nn.Linear(1040, 1, bias=True)\n","\n","  def forward(self, x_iris, x_face):           # x_iris = torch.Size([batch_size, 1, 512, 64]) # x_face = torch.Size([batch_size, 1, 1, 512])\n","      x_iris = x_iris.permute(0,1,3,2)         # torch.Size([batch_size, 1, 64, 512])\n","      y = torch.cat((x_iris,x_face),2)         # torch.Size([batch_size, 1, 65, 512])\n","      y = self.layer3(self.layer2(self.layer1(y)))   # torch.Size([batch_size, 1, 65, 256])          \n","      y = self.layer6(self.layer5(self.layer4(y)))   # torch.Size([batch_size, 1, 65, 16])\n","      y = y.view(y.size(0), -1)            # torch.Size([batch_size, 1040])\n","      y = self.layer7(y)                # torch.Size([batch_size, 1])\n","      return y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"i_J4j-YVh1ba","colab_type":"code","colab":{}},"source":["# train set\n","def default_loader(path):\n","    return loadmat(path)['output']\n","\n","class MyDataset(Dataset):\n","  def __init__(self, txt, transform=None, target_transform=None, loader=default_loader):\n","    super(MyDataset,self).__init__()\n","    fh = open(txt, 'r')\n","    feats = []\n","    for line in fh:\n","      line = line.strip('\\n')                      \n","      line = line.rstrip('\\n')                     \n","      words = line.split()\n","      feats.append(('IITD/IITD_train_feat/'+words[0], 'LFW/LFW_train_feat/'+words[0], float(words[1])))\n","    self.feats = feats\n","    self.transform = transform\n","    self.target_transform = target_transform\n","    self.loader = loader\n","  def __getitem__(self, index):\n","    f1, f2, label = self.feats[index]\n","    feat1 = self.loader(f1)\n","    feat2 = self.loader(f2)\n","    if self.transform is not None:\n","      feat1 = self.transform(feat1)\n","      feat2 = self.transform(feat2)\n","    return feat1,feat2,label\n","  def __len__(self):\n","    return len(self.feats)\n","\n","train_data = MyDataset(txt='train.txt', transform=transforms.ToTensor())\n","train_loader = DataLoader(dataset=train_data, batch_size=40, shuffle=False)\n","print('num_of_trainData:', len(train_data))\n","print('num_of_train_loader:', len(train_loader))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qSiuGBPEK55E","colab_type":"code","colab":{}},"source":["# train\n","model = FaceIrisQANet()\n","if torch.cuda.is_available():\n","  model = model.cuda()\n","model.load_state_dict(torch.load('FaceIrisQANet_params.pkl'))\n","criterion = nn.L1Loss()\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=20, verbose=False, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08)\n","\n","train_loss_min = np.Inf\n","for epoch in range(500):\n","  train_loss = 0.0\n","  for data in train_loader:\n","    IrisFeat, FaceFeat, label = data\n","    if torch.cuda.is_available():\n","        IrisFeat = IrisFeat.cuda()\n","        FaceFeat = FaceFeat.cuda()\n","        label = label.cuda()\n","    else:\n","        IrisFeat = Variable(IrisFeat)\n","        FaceFeat = Variable(FaceFeat)\n","        label = Variable(label)\n","    target = torch.unsqueeze(label,1)\n","    optimizer.zero_grad()\n","    out = model(IrisFeat, FaceFeat)\n","    loss = criterion(out, target.float())\n","    loss.backward()\n","    optimizer.step()\n","    train_loss += loss.item()*IrisFeat.size(0)\n","  train_loss = train_loss/len(train_loader.dataset)\n","  scheduler.step(train_loss)\n","  print('LR: {} Epoch: {} \\tTraining Loss: {:.6f}'.format(optimizer.state_dict()['param_groups'][0]['lr'], epoch, train_loss))  \n","  # save model if Train loss has decreased\n","  if train_loss < train_loss_min:\n","    print('train loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(train_loss_min, train_loss))\n","    torch.save(model.state_dict(), 'FaceIrisQANet_params.pkl')\n","    train_loss_min = train_loss\n","  if train_loss < 0.001:\n","    print('train loss has met the need')\n","    break"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vp0pd8MFAH9F","colab_type":"code","colab":{}},"source":["# test set\n","def default_loader(path):\n","    return loadmat(path)['output']\n","\n","class MyDataset(Dataset):\n","  def __init__(self, txt, transform=None, target_transform=None, loader=default_loader):\n","    super(MyDataset,self).__init__()\n","    fh = open(txt, 'r')\n","    feats = []\n","    for line in fh:\n","      line = line.strip('\\n')    \n","      line = line.rstrip('\\n')    \n","      words = line.split()\n","      feats.append(('IITD/IITD_test_feat/'+words[0], 'LFW/LFW_test_feat/'+words[0]))\n","    self.feats = feats\n","    self.transform = transform\n","    self.target_transform = target_transform\n","    self.loader = loader\n","  def __getitem__(self, index):\n","    f1, f2 = self.feats[index]\n","    feat1 = self.loader(f1)\n","    feat2 = self.loader(f2)\n","    if self.transform is not None:\n","      feat1 = self.transform(feat1)\n","      feat2 = self.transform(feat2)\n","    return feat1, feat2\n","  def __len__(self):\n","    return len(self.feats)\n","\n","test_data = MyDataset(txt='test.txt', transform=transforms.ToTensor())\n","test_loader = DataLoader(dataset=test_data, batch_size=40, shuffle=False)\n","print('num_of_testData:', len(test_data))\n","print('num_of_test_loader:', len(test_loader))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XmvxpdJRLlg_","colab_type":"code","colab":{}},"source":["# test\n","model = FaceIrisQANet()\n","if torch.cuda.is_available():\n","  model = model.cuda()\n","model.load_state_dict(torch.load('FaceIrisQANet_params.pkl'))\n","iris_score = [[1]]\n","\n","for data in test_loader:\n","  IrisFeat, FaceFeat, label = data\n","  if torch.cuda.is_available():\n","      IrisFeat = IrisFeat.cuda()\n","      FaceFeat = FaceFeat.cuda()\n","  else:\n","      IrisFeat = Variable(IrisFeat)\n","      FaceFeat = Variable(FaceFeat)\n","  out = model(IrisFeat, FaceFeat)   \n","  iris_score = np.append(iris_score,out.cpu().detach().numpy(),axis=0)\n","  print(np.shape(iris_score))\n","\n","iris_score = np.delete(iris_score,0,axis=0)\n","iris_score = iris_score.T\n","savemat('IITD_LFW_test_quality_score.mat',{'iris_score':iris_score})"],"execution_count":0,"outputs":[]}]}